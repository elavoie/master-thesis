\chapter{Conclusion}
\label{chap:Conclusion}

\funnyquote{The end is the beginning of all things,\\
Suppressed and hidden,\\
Awaiting to be released through the rhythm\\
Of pain and pleasure}
{Jiddu Krishnamurti}

\funnyquote{Now this is not the end. It is not even the beginning of the end. But
it is, perharps, the end of the beginning.}
{Winston Churchill}


In the preceding chapters we saw how a metacircular VM targeting its source
language, based on a message-sending object model could provide flexible
run-time instrumentation of the object model and function-calling protocol at a
baseline performance within a factor of two of a state-of-the-art interpreter, by
harnessing a sophisticated run-time optimizer, without having to modify the
underlying VM source code. The motivation for the work stems from our current
inability to obtain longitudinal data on the behavior of JavaScript programs
because of the effort involved with the current approach, namely to manually
instrument a production interpreter and maintain it up-to-date. This
dissertation explained how to solve the core technical issue behind this state
of affairs, by harnessing the performance gains obtained in recent years for
flexibility.

However, there is still some work to be performed to \textit{actually} use
those results to gather empirical data about JavaScript programs. At the same
time, the approach suggests other possible uses which might be worth exploring.
In the next sections, we discuss the limitations of the current prototype, with
regard to its JavaScript implementation, and we identify how the approach could
be broadly applied by improving upon our current results.

\section{Limitations}

The limitiations of our current prototype come from JavaScript peculiarities
that could easily be eliminated if the next versions of the standard were
allowed to relax strict backward compatibility. Another option would be
to perform run-time checks to ensure they never arise.  However, we conjecture
that the resulting system is more useful by relaxing the strict adherence to
the behavior expected from current VMs for substantial performance gains.  In
the face of numerous quirks and warts in the design of the JavaScript language,
it is more important to provide a useful and powerful system, but potentially
incorrect, than an unuseful but correct one.

\subsection{Accessing the \kw{__proto__} property leaks the internal representation}

This limitation can affect the soundness of the program. This could have been
solved at the design stage of JavaScript, if the access to the prototype of an
object has been made through a method call, such as \kw{getPrototype()} instead
of by accessing the \kw{__proto__} property. This is a problem of mixing
meta-level with base-level information.

The problem can be mitigated with no run-time penalty by detecting, at
compile-time, accesses to the \kw{__proto__} property and calling the object
representation \kw{getProtype} method instead. However, the possibility of
dynamically generating the \kw{__proto__} name render it unsound. It
is yet to be seen if this actually happens in the wild.

\subsection{Meta-methods can conflict with regular methods if they have the same name}

This limitation will be solved in the next version of the standard, when
unforgeable names will be available in user space.  Until then, we can rely on
little used names to minimize possible conflicts with existing code.

\subsection{Setting the \kw{__proto__} property throws an exception}

This might be fixed by invalidating all caches should the prototype of an
object changes. A more sophisticated mecanism could be devised if the operation
is frequent.

\subsection{Operations on \kw{null} or \kw{undefined} might throw a different exception}

When trying to access a property or call a method on the \kw{null} or
\kw{undefined} value, VMs for JS throw an exception telling the user that the
property or the method does not exist on the object. Our current design reify
property accesses as a call to the \kw{get} method on the object representation
and calls as a call to the \kw{call} method, \textit{once the object operation
has been cached}. If the receiver is \kw{null} or \kw{undefined} the exception
will tell of a missing method that is different from the property or the method
called.

This problem actually only happens when instrumenting incorrect programs. It
might not be a problem at all when browsing the web. Otherwise, it would be
possible to test for \kw{null} or \kw{undefiend} on every operations, at a
substantial run-time cost.

Another option would be to change the exception being raised by adding test and
patch code for that particular exception at every catch site, at a
potentially more reasonable cost depending on the actual usage of the catch
construct.

This is fundamentally a problem of non-uniformity in the object model. It would
not exist if every value was an object.  This could be fixed in a subsequent
revision of JavaScript by providing auto-boxing of \kw{null} and
\kw{undefined}, in a similar fashion as what is done for other primitive types,
and adding a "does not understand" handler for property accesses and method
calls that could be overwritten. The default behavior could be to raise an
exception when accessing, setting or deleting a property or calling a method.
The prototype object for \kw{undefined} and \kw{null} could then have methods that
raise proper exceptions.

\subsection{Limited support for eval}

Our compiler does not support accessing the local environment of a function
from evaluated code. This can be fixed by maintaining on functions the
environment information. This environment can than be provided to our compiler,
when it is called during and \kw{eval} operation.

\subsection{Function calls implicitly made by the standard library are not intercepted}

Functions passed to the standard library are wrapped to remove the extra
arguments introduced by our compilation strategy. Should the need to intercept
those calls arise, the wrappers could perform a message send instead of a
direct call.
 
\section{Future Work}

The obvious short term work would be to package the system in a browser
extension for Firefox or Chrome and use it to try to replicate the results
obtained on the dynamic behavior of JavaScript programs~\cite{behavior_js}, to
see if they still hold and try the instrumentation on more than just the 100
more popular websites. Then we could extend the instrumentation to cover not
only the object model operations and function calls but also the binary, unary,
control-flow and reflexive operations.

We believe there is much more potential to the current approach. The
biggest open question is how close can we come to native performance while
providing flexibility unavailable in the vanilla implementation. We compared
ourselves to a state-of-the-art interpreter because this is what is being used
for instrumentation nowadays. Similar performance is therefore enough for
obtaining information about the dynamic behavior of JavaScript programs. 

We argue that as virtual machines for dynamic languages become faster and
incorporate more sophisticated optimization techniques, the implementation
techniques for layered VMs should become worthy of research efforts since they
have the potential to provide an efficient way of supporting numerous languages
with limited efforts. This dissertation is a step in that direction.

Also, there could be qualitative improvements if the performance was much
better, by opening whole new possibilities of applications.  In the next
sections, we reflect about possible approaches to improve efficiency
using known techniques.

\subsection{Improve compilation speed}

Our OMeta-based compiler~\cite{Warth:2007} can be significantly slow during the
parsing stage. If compilation speed becomes critical, it could be replaced with
a different algorithm or the OMeta runtime and compiled code could be
optimized.

\subsection{Allow a finer-grained redefinition of meta-methods}

Object-model operations can only be redefined on the root object, mostly to
simplify the tracking mecanism. A more sophisticated tracking mecanism could
allow object model operations to be redefined for subsets of all objects by
redefining the operation at the appropriate place on the inheritance hierarchy.

\subsection{Efficient instrumentation}

There are two major areas for optimizations: the baseline performance of the
system and the performance while the code is instrumented. We briefly touch
upon each of them. 

\subsubsection{Improve the baseline performance}

The easiest known technique that would be worth trying to replicate in a
metacircular setting is the dynamic recompilation of the source code based on
type-feedback obtained during execution. It would further allow the
specialization of the code to the actual types occuring during execution and
the removal of message-sending caches for operations that have not been
redefined.

Our current object representation makes it easy by wrapping the function being
executed.  The function could be replaced at run time with a specialized
version. This could eliminate type tests and specialize functions used as
constructors. Our current inline cache design allows the accumulation of
arbitrary information which could be used for that purpose.

The other technique to be tried is the object represention method
specialization presented in the design section. Further gains could be had if
both the lookup and the argument specialization were combined in a single
method.

\subsubsection{Provide mecanisms to optimize the instrumentation code}

First, the system internals currently use a memoization protocol to specialize base
operations. By exposing the mecanism to user code, this would allow analyses to
specialize their behavior based on previous executions. This could notably be
used to avoid performing operations in expensive data structures the second
time.

Second, the system could offer a better granularity of instrumentation.
Currently, instrumenting a base operation applies to all objects. However, if
we could target only a subset of objects and handle that subset at the cache
level, we could avoid the instrumentation cost for a majority of objects. This
could be done by implementing the equivalent of polymorphic inline caches and
having a finer-grained tracking mecanism for cache states.


%\subsection{Real-time analysis of the behavior of JavaScript programs}
%
%A sufficient performance could allow a real-time analysis of the behavior of
%JavaScript programs. Compared to the log and analyse approach previously
%done~\cite{behavior_js}, this could provide a qualitatively different
%experience.
%
%This could be used by web developers to develop an intuition about the
%performance cost of various operations. This could also be used by the
%JavaScript committee to develop a better idea of what features are actually
%used accross the web and could allow the deprecation of features that are never
%used.
%
%\subsection{Simplification of production VMs}
%
%Some little-used features (or quirks!) of the JavaScript languages hold back
%the performance that could be achievable and are maintained for
%backward-compatibility reasons. Those features could be provided by a
%metacircular VM through newer and better performing features.  The
%metacircular VM could be loaded lazily only when the old features are actually
%invoked.
%
%\subsection{Server-side instrumentation}
%
%A server could dynamically choose to send an instrumented version of its
%JavaScript code to gather information about the actual usage made by users of
%the application. While executing, the instrumented library could "phone home"
%to send back profiling information. However, due to access restrictions in the
%browser, a server configuration is required to permit the direct communication
%of the instrumented code with the library developer server.
%
%\subsection{Library-based profiling}
%
%It is currently hard for library developers to know precisely what
%functionalities are actually used and in which context. It could be possible to
%provide a pre-instrumented library version, tailored to the questions the
%library developers would like to be answered that other web developers could
%use in their web pages. 
%
%\subsection{Server code instrumentation}
%
%%The emergence of NodeJS as a server environment obviously allows the system to
%gather information about server-side code.
%
%\subsection{Security invariants monitoring}
%
%Instrumentation could be performed to enforce security invariants instead of
%only logging operations. 
